{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>3</td><td>application_1604941853369_0007</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-172-31-47-65.eu-west-3.compute.internal:20888/proxy/application_1604941853369_0007/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-172-31-36-29.eu-west-3.compute.internal:8042/node/containerlogs/container_1604941853369_0007_01_000001/livy\">Link</a></td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<SparkContext master=yarn appName=livy-session-3>"
     ]
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql.types import *\n",
    "import pandas as pd\n",
    "pd.options.display.max_columns = None\n",
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px solid blue\"></hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LOADING DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download Dataset & Load into HDFS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "sudo su \n",
    "cd \n",
    "mkdir mov\n",
    "cd mov\n",
    "\n",
    "wget http://files.grouplens.org/datasets/movielens/ml-latest.zip\n",
    "unzip ml-latest.zip\n",
    "rm -f ml-latest.zip\n",
    "\n",
    "hdfs dfs -mkdir /user/root/data/\n",
    "hdfs dfs -mkdir /user/root/data/MOV/\n",
    "hdfs dfs -mkdir /user/root/data/MOV/CSV\n",
    "\n",
    "hdfs dfs -put ml-latest/* /user/root/data/MOV/CSV\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define schema for Movies Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "moviesStruct = [StructField(\"movieId\", IntegerType(), True),\n",
    "    StructField(\"title\", StringType(), True),\n",
    "    StructField(\"genres\", StringType(), True)]\n",
    "\n",
    "moviesSchema = StructType(moviesStruct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read Movies dataframe from HDFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Read movies from HDFS as CSV (FIRST TIME ONLY)\n",
    "\n",
    "moviesDF = spark.read.format(\"csv\") \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"delimiter\", \",\") \\\n",
    "    .schema(moviesSchema) \\\n",
    "    .load(\"hdfs:///user/root/data/MOV/CSV/movies.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write Movies Dataframe to Parquet File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moviesDF.write.parquet(\"hdfs:///user/root/data/MOV/PARQUET/movies.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reload Movies Dataframe From Parquet File "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# (everytime after the first export to PARQUET)\n",
    "\n",
    "moviesDF = spark.read.parquet(\"hdfs:///user/root/data/MOV/PARQUET/movies.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make Use of Caching Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame[movieId: int, title: string, genres: string]"
     ]
    }
   ],
   "source": [
    "# caching might be aof great help for crossvalidation -among others\n",
    "# read caching comment for ratingsDF below\n",
    "\n",
    "moviesDF.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define schema for Ratings Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define schema for ratings dataset\n",
    "ratingsStruct = [StructField(\"userId\", IntegerType(), True),\n",
    "    StructField(\"movieId\", IntegerType(), True),\n",
    "    StructField(\"rating\", DoubleType(), True),\n",
    "    StructField(\"timestamp\", IntegerType(), True)]\n",
    "\n",
    "ratingsSchema = StructType(ratingsStruct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read Ratings Dataframe from HDFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   userId  movieId  rating   timestamp\n",
      "0       1      307     3.5  1256677221\n",
      "1       1      481     3.5  1256677456\n",
      "2       1     1091     1.5  1256677471\n",
      "3       1     1257     4.5  1256677460\n",
      "4       1     1449     4.5  1256677264\n",
      "5       1     1590     2.5  1256677236\n",
      "6       1     1591     1.5  1256677475\n",
      "7       1     2134     4.5  1256677464\n",
      "8       1     2478     4.0  1256677239\n",
      "9       1     2840     3.0  1256677500"
     ]
    }
   ],
   "source": [
    "# Read ratings from HDFS (FIRST TIME ONLY)\n",
    "ratingsDF = spark.read.format(\"csv\") \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"delimiter\", \",\") \\\n",
    "    .schema(ratingsSchema) \\\n",
    "    .load(\"hdfs:///user/root/data/MOV/CSV/ratings.csv\")\n",
    "\n",
    "ratingsDF.limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write Ratings Dataframe to Parquet File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratingsDF.write.parquet(\"hdfs:///user/root/data/MOV/PARQUET/ratings.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reload Ratings Dataframe From Parquet File "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# LOAD RATINGS From Parquet File (everytime after the first export to PARQUEY)\n",
    "\n",
    "ratingsDF = spark.read.parquet(\"hdfs:///user/root/data/MOV/PARQUET/ratings.parquet\").drop(\"timestamp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make Use of Caching Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame[userId: int, movieId: int, rating: double]"
     ]
    }
   ],
   "source": [
    "# Caching might be of great help - especially for crossvalidation -among others\n",
    "# it is recommended for RDD re-use in iterative machine learning applications\n",
    "# Check the size of your data on disk, and the total memory available to spark\n",
    "# to see how much of your data fits into memory\n",
    "# If the RDD does not fit in memory, some partitions will not be cached and will be recomputed on the fly each time they're needed. \n",
    "\n",
    "ratingsDF.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px solid blue\"></hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Exploration & Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select Users Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Unique Users Id :\n",
    "usersDF = ratingsDF.select(\"userId\").distinct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "283228"
     ]
    }
   ],
   "source": [
    "# Total User Count\n",
    "\n",
    "usersDF.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['userId']"
     ]
    }
   ],
   "source": [
    "usersDF.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Group Rating Count by Users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|userId|count|\n",
      "+------+-----+\n",
      "|148   |48   |\n",
      "|496   |31   |\n",
      "|833   |17   |\n",
      "|1088  |5    |\n",
      "|1342  |3    |\n",
      "|1591  |52   |\n",
      "|2122  |88   |\n",
      "|2366  |25   |\n",
      "|3918  |49   |\n",
      "|4101  |3    |\n",
      "+------+-----+\n",
      "only showing top 10 rows"
     ]
    }
   ],
   "source": [
    "ratingsDF.groupBy(\"userId\").count().show(10, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary \n",
    "# Got 1000209 ratings from 6040 users on 3883 movies.\n",
    "print(\"Got {} ratings from {} users on {} movies.\".format(ratingsDF.count(), usersDF.count(), moviesDF.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ratingsDF.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select Max User ID \n",
    "This will be useful for user incrementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ratingsDF.agg({\"userId\": \"max\"}).collect()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ratingsDF.schema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Ratings View"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratingsDF.createTempView(\"RATING\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use SQL to select Ratings for a specific User"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "select * from RATING where userId = 283228"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "select count(*) from RATING where userId = 283228"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a Sample Dataframe \n",
    "(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sampleDF = moviesDF.sample(fraction=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px solid blue\"></hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring Movies Dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select Comedy Movies Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "moviesDF.filter(moviesDF.genres.contains('Comedy')).limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display the TOP rated Comedy Movies (not aggregated)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "moviesDF.filter(moviesDf.genres.contains('Comedy')) \\\n",
    "    .join(ratingsDF, \"movieId\") \\\n",
    "    .sort(col(\"rating\").desc()) \\\n",
    "    .show(20, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Count of Comedy Movies Grouped By Rating "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "moviesDF.filter(moviesDF.genres.contains('Comedy')) \\\n",
    "    .join(ratingsDF, \"movieId\") \\\n",
    "    .groupBy(col(\"rating\")).count().orderBy(\"rating\") \\\n",
    "    .show(20, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MOST Rated Comedy Movies - No matter the rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "moviesDF.filter(moviesDf.genres.contains('Comedy')) \\\n",
    "    .join(ratingsDF, \"movieId\") \\\n",
    "    .groupBy(col(\"movieId\")).count().orderBy(\"count\", ascending=False) \\\n",
    "    .show(20, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Most Rated Comedy Movies, grouped by Movie & Rating\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "moviesDF.filter(moviesDf.genres.contains('Comedy')) \\\n",
    "    .join(ratingsDF, \"movieId\") \\\n",
    "    .groupBy(col(\"movieId\"),col(\"title\"), col(\"rating\")).count().orderBy(\"count\", ascending=False) \\\n",
    "    .show(20, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Top Rated Comedy Movies with most ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "genreMovieDF = moviesDF.filter(moviesDF.genres.contains(genre))\n",
    "    \n",
    "moviesByRating_counts = genreMovieDF \\\n",
    "        .join(ratingsDF, \"movieId\") \\\n",
    "        .groupBy(\"movieId\").count().alias(\"count\").orderBy(desc(\"count\"))\n",
    "        #.groupBy(\"movieId\").count().alias(\"ratings count\").orderBy(desc(\"count\"))\n",
    "\n",
    "moviesByRating_Full = genreMovieDF.join(moviesByRating_counts, \"movieId\") \\\n",
    "                                  .dropDuplicates().orderBy(desc(\"count\"))\n",
    "    \n",
    "movieByRating_full.show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "movieByRating_Full.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movieByRating_Full.coalesce(1) \\\n",
    "      .write \\\n",
    "      .option(\"header\",\"true\") \\\n",
    "      .option(\"sep\",\",\") \\\n",
    "      .mode(\"overwrite\") \\\n",
    "      .csv(\"file:///path/output/file\") \\"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get User Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Cell does not work on Jupyter unfortunately \n",
    "# due to Pyspark limited Python libraries integration\n",
    "# This need py4j integration and a call to scala/java\n",
    "# code for that is provided as a standalone pyton program\n",
    "\n",
    "\n",
    "for row in sampleDf.rdd.collect():\n",
    "    print(\"Please rate the following movie (1-5 (best), or 0 if not seen):\\n\" + row.title + \":\")\n",
    "    rate = int(input())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "joinDf = moviesDf.join(ratingsDf, \"movieId\")\n",
    "joinDf.show(10, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ratingsDF.distinct().groupBy(\"rating\").count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px solid blue\"></hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODELING PART\n",
    "\n",
    "### Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting data into training & test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "trainingDF,testDF = ratingsDF.randomSplit([0.8, 0.2], seed=12345)\n",
    "\n",
    "# Got 1000209 ratings from 6040 users on 3883 movies.\n",
    "#print(\"Training {}, test {}.\".format(trainingDF.count(), testDF.count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Timing Utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from time import time\n",
    "from datetime import timedelta\n",
    "\n",
    "class T():\n",
    "    def __enter__(self):\n",
    "        self.start = time()\n",
    "    def __exit__(self, type, value, traceback):\n",
    "        self.end = time()\n",
    "        elapsed = self.end - self.start\n",
    "        print(str(timedelta(seconds=elapsed)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame[userId: int, movieId: int, rating: double, timestamp: int]"
     ]
    }
   ],
   "source": [
    "trainingDF.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame[userId: int, movieId: int, rating: double, timestamp: int]"
     ]
    }
   ],
   "source": [
    "testDF.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "281954"
     ]
    }
   ],
   "source": [
    "trainingDF.select(\"userId\").distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "264083"
     ]
    }
   ],
   "source": [
    "testDF.select(\"userId\").distinct().count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point it is interesting to see that there might be users on the test dataset  \n",
    "that have no occurence in the training dataset, as the figures below can possibly suggest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training ALS model on the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "from pyspark.ml.recommendation import ALS\n",
    "\n",
    "als = ALS(maxIter=5,\n",
    "          regParam=0.01, \n",
    "          implicitPrefs=False, \n",
    "          userCol=\"userId\", \n",
    "          itemCol=\"movieId\", \n",
    "          ratingCol=\"rating\", \n",
    "          coldStartStrategy=\"drop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:01:02.987745"
     ]
    }
   ],
   "source": [
    "# Fit Model (just a test - DO NOT RUN if you still need to cross-validate)\n",
    "\n",
    "with T():\n",
    "    model = als.fit(trainingDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px solid blue\"></hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation & Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "\n",
    "# WARNING : THIS CAN ESCALATE VERY QUICKLY, EVEN WITH ONLY TWO MODELS TO BE TESTED\n",
    "# UNLESS YOU ARE ABLE TO NARROW DOWN AND LOWER ITERATIONS CONSIDERABLY, \n",
    "# YOU WOULD BETTER AVOID THIS STEP ALL TOGETHER\n",
    "\n",
    "# NOTE THAT USING AN RMSE MINIMIZING LOOP CAN ALSO DO THE JOB\n",
    "\n",
    "#param_grid = ParamGridBuilder() \\\n",
    "#            .addGrid(als.rank, [10, 50, 100, 150]) \\\n",
    "#            .addGrid(als.regParam, [.01, .05, .1, .15]) \\\n",
    "#            .build()\n",
    "\n",
    "#param_grid = ParamGridBuilder() \\\n",
    "#            .addGrid(als.rank, [50, 100]) \\\n",
    "#            .addGrid(als.regParam, [.05, .1]) \\\n",
    "#            .build()\n",
    "\n",
    "param_grid = ParamGridBuilder() \\\n",
    "            .addGrid(als.rank, [50]) \\\n",
    "            .addGrid(als.regParam, [.05]) \\\n",
    "            .build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "# Define evaluator as RMSE and print length of evaluator\n",
    "evaluator = RegressionEvaluator(\n",
    "           metricName=\"rmse\", \n",
    "           labelCol=\"rating\", \n",
    "           predictionCol=\"prediction\") \n",
    "\n",
    "print (\"Num models to be tested: \", len(param_grid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CrossValidator(estimator=als, \\\n",
    "                    estimatorParamMaps=param_grid, \\\n",
    "                    evaluator=evaluator, \\\n",
    "                    numFolds=5\n",
    "                    parallelism=4) # this last parallelism param is crucial for increasing performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit The Cross Validator \n",
    "#### *(Optional - VERY Time Consuming)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# WARNING : Running this from a notebook hooked to Spark through Livy \n",
    "# will end up in a timeout after waiting for a long time\n",
    "# the job will still be running but it will be abruptly be killed due to a timeout setting\n",
    "# you need to setup livy.server.session.timeout and extend it to 1h  in livy.conf on the server, and restart livy\n",
    "# livy.server.session.state-retain.sec = 600s => move to 3600s \n",
    "# location : /etc/livy/conf/livy.conf\n",
    "\n",
    "# check spark web UI\n",
    "# check generated DAGs\n",
    "# check memory usage\n",
    "\n",
    "cvModel = cv.fit(trainingDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px solid blue\"></hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Evaluate the model by computing the RMSE on the Rating Predictions established for test data\n",
    "\n",
    "predictions = model.transform(testDF)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['userId', 'movieId', 'rating', 'prediction']"
     ]
    }
   ],
   "source": [
    "predictions.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trainingDF.filter(testDF.userId == \"12\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+\n",
      "|userId|movieId|rating|\n",
      "+------+-------+------+\n",
      "|    12|     48|   2.5|\n",
      "+------+-------+------+"
     ]
    }
   ],
   "source": [
    "testDF.filter(testDF.userId == \"12\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "testDF.show(10, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "testDF.groupBy(\"userId\").count().show(10, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+----------+\n",
      "|userId|movieId|rating|prediction|\n",
      "+------+-------+------+----------+\n",
      "|12    |48     |2.5   |1.1086082 |\n",
      "|65    |1291   |5.0   |3.00573   |\n",
      "|65    |5952   |5.0   |3.584456  |\n",
      "|65    |54286  |3.0   |4.1214256 |\n",
      "|76    |356    |5.0   |3.7495227 |\n",
      "|76    |457    |4.0   |3.3255415 |\n",
      "|76    |1240   |5.0   |3.1485655 |\n",
      "|76    |2329   |4.0   |3.980468  |\n",
      "|76    |2712   |1.0   |2.7749074 |\n",
      "|76    |2763   |3.5   |2.5788736 |\n",
      "+------+-------+------+----------+\n",
      "only showing top 10 rows\n",
      "\n",
      "0:00:12.380447"
     ]
    }
   ],
   "source": [
    "with T():\n",
    "    predictions.show(10, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predictions.groupBy(\"userId\").count().show(10, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate using Regression Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\",\n",
    "                                predictionCol=\"prediction\")\n",
    "\n",
    "# Lower values of RMSE indicate better fit\n",
    "\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(\"Root-mean-square error = \" + str(rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px solid blue\"></hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Utilization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate recommendations for each user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CAUTION : This takes too much time to compute\n",
    "# Use subsets instead (cell below)\n",
    "\n",
    "# Generate top 10 movie recommendations for each user\n",
    "userRecs = model.recommendForAllUsers(10)\n",
    "\n",
    "# Generate top 10 user recommendations for each movie\n",
    "movieRecs = model.recommendForAllItems(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate recommendations for a subset of user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generate top 10 movie recommendations for a specified set of users\n",
    "users = ratingsDF.select(als.getUserCol()).distinct().limit(3)\n",
    "userSubsetRecs = model.recommendForUserSubset(users, 10)\n",
    "\n",
    "# Generate top 10 user recommendations for a specified set of movies\n",
    "movies = ratingsDF.select(als.getItemCol()).distinct().limit(3)\n",
    "movieSubSetRecs = model.recommendForItemSubset(movies, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "userSubsetRecs.show(10, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   userId                                    recommendations\n",
      "0    1311  [(160824, 12.564236640930176), (121650, 9.9915...\n",
      "1    1306  [(160824, 15.04566478729248), (186347, 13.2301...\n",
      "2    1774  [(115840, 15.921332359313965), (88816, 13.7468..."
     ]
    }
   ],
   "source": [
    "userSubsetRecs.limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px solid blue\"></hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get model recommendation for users based on their rating \n",
    "# You will notice that the Returned Dataframe has nested values \n",
    "# DataFrame[userId: int, recommendations: array<struct<movieId:int,rating:float>>]\n",
    "# You will also notice that predicted ratings are all over the place\n",
    "# This is not strictly an issue as it is not used \"directly\" and it can be ignored. \n",
    "# For more info see: https://stackoverflow.com/q/29051520/426332\n",
    "\n",
    "recoDF = userSubsetRecs.limit(10)\n",
    "#.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Formatting & Join for staging & presentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    userId  movieId                                              title\n",
      "0      148   119165                                 Lunch Break (2008)\n",
      "1      148   121650                          The Loyal 47 Ronin (1958)\n",
      "2      148   129516                                      Poison (1951)\n",
      "3      148   141532                                   Retrieval (2006)\n",
      "4      148   154580                              Remote Control (1992)\n",
      "5      148   154598                                  I, a Woman (1965)\n",
      "6      148   159467                   Fifi Howls from Happiness (2013)\n",
      "7      148   160824                  W.A.R.: Women Against Rape (1987)\n",
      "8      148   189325                                         The Change\n",
      "9      148   191203                                 Ô Jerusalem (2006)\n",
      "10     496    90533                            Marseillaise, La (1938)\n",
      "11     496   119165                                 Lunch Break (2008)\n",
      "12     496   121650                          The Loyal 47 Ronin (1958)\n",
      "13     496   124853                             Why Man Creates (1968)\n",
      "14     496   145893                             Special Section (1975)\n",
      "15     496   159467                   Fifi Howls from Happiness (2013)\n",
      "16     496   160824                  W.A.R.: Women Against Rape (1987)\n",
      "17     496   162436                UFO - Distruggete base Luna! (1971)\n",
      "18     496   188001                    Barankin, bud chelovekom (1962)\n",
      "19     496   189325                                         The Change\n",
      "20     833    77470  Stray Cat Rock: Sex Hunter (Nora-neko rokku: S...\n",
      "21     833   117726              Russell Brand: Messiah Complex (2013)\n",
      "22     833   121650                          The Loyal 47 Ronin (1958)\n",
      "23     833   131620                            Little White Lie (2014)\n",
      "24     833   144210             Just Eat It: A Food Waste Story (2014)\n",
      "25     833   159467                   Fifi Howls from Happiness (2013)\n",
      "26     833   160824                  W.A.R.: Women Against Rape (1987)\n",
      "27     833   162436                UFO - Distruggete base Luna! (1971)\n",
      "28     833   169268  Cedric the Entertainer: Live from the Ville (2...\n",
      "29     833   186347                                Extinct Pink (1969)"
     ]
    }
   ],
   "source": [
    "\n",
    "# Denormalize Recommendation Dataframe & explode the inner list so it can be selectable as a column   \n",
    "# and filter out the rating colums as we do not need it\n",
    "\n",
    "recoDF.select(col(\"userId\"),explode(col(\"recommendations\"))) \\\n",
    "      .select(col(\"userId\"),col(\"col.movieId\")) \\\n",
    "      .join(moviesDF,\"movieId\") \\\n",
    "      .orderBy(\"userId\") \\\n",
    "      .select(\"userId\", \"movieId\", \"title\") \\\n",
    "      .toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "movieSubSetRecs.show(10, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Recommendations for a specific user\n",
    "aUserId = 12\n",
    "recommandations = userRecs.filter(col(\"userId\") == aUserId)\n",
    "recommandations.show(1, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import explode\n",
    "\n",
    "# Let's flatten the movie recommandations and look in detail\n",
    "userRecommandations = recommandations.select(\n",
    "  explode(col(\"recommendations\").movieId).alias(\"movieId\")\n",
    ")\n",
    "\n",
    "print(\"Recommandations for user {} :\".format(aUserId))\n",
    "\n",
    "moviesDf.join(userRecommandations, \"movieId\").show(10, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Ratings from the user\n",
    "\n",
    "ratingsDF.filter(col(\"userId\") == aUserId) \\\n",
    "    .join(moviesDf, \"movieId\") \\\n",
    "    .sort(col(\"rating\").desc()) \\\n",
    "    .show(100, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px solid blue\"></hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log Model Experiments with MLFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Make SURE to read carefully the MLFLOW REAMDE FILE first\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import mlflow\n",
    "import mlflow.spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#not necessary as it defaults to /mlruns\n",
    "# mlflow.set_tracking_uri(\"file:///path/to/mlruns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mlflow.set_tracking_uri(\"file:///mlruns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<ActiveRun: >"
     ]
    }
   ],
   "source": [
    "mlflow.start_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mlflow.spark.log_model(model, \"ALSmodel_Lite8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Model saved in run %s\" % mlflow.active_run().info.run_uuid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Run MLFlow UI to check your model**\n",
    "```\n",
    "mlflow ui --backend-store-uri /mlrun --host 0.0.0.0&\n",
    "```\n",
    "\n",
    "go to http://YOUR.IP.ADD.RESS:5000 :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Serve Model with MLFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```console\n",
    "# Serve & Curl Request Examples  \n",
    "(Make SURE to read carefully the MLFLOW REAMDE FILE first)\n",
    "\n",
    "mlflow models serve -m /mlruns/0/6c8050941d0744b8ac3652ff22d40983/artifacts/ALSmodel_Lite2 -h 0.0.0.0 --port 9999 --no-conda\n",
    "\n",
    "\n",
    "curl -X POST localhost:9999/invocations -H 'Content-Type: application/json; format=pandas-split' -d '{\"columns\":[\"userId\",\"movieId\",\"rating\"], \"data\":[[1311,144210,5,1604450652]]}'  \n",
    "\n",
    "curl --request POST http://localhost:9999/invocations --header 'Content-Type: application/json; format=pandas-split' --data @mlf_data.json\n",
    "\n",
    "curl -X POST http://localhost:9999/invocations -H 'Content-Type: application/json; format=pandas-split' -d @mlf_data.json\n",
    "```\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
