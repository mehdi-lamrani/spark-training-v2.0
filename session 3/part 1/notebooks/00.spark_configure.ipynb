{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>43</td><td>application_1602760145222_25365</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-172-31-9-23.eu-west-3.compute.internal:20888/proxy/application_1602760145222_25365/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-172-31-6-132.eu-west-3.compute.internal:8042/node/containerlogs/container_1602760145222_25365_01_000001/livy\">Link</a></td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('spark.submit.pyFiles', '/usr/lib/spark/python/lib/pyspark.zip,/usr/lib/spark/python/lib/py4j-0.10.9-src.zip'), ('spark.eventLog.enabled', 'true'), ('spark.executor.memory', '9486M'), ('spark.jars', 'file:/usr/lib/livy/rsc-jars/livy-api-0.7.0-incubating.jar,file:/usr/lib/livy/rsc-jars/livy-rsc-0.7.0-incubating.jar,file:/usr/lib/livy/rsc-jars/livy-thriftserver-session-0.7.0-incubating.jar,file:/usr/lib/livy/rsc-jars/netty-all-4.1.17.Final.jar,file:/usr/lib/livy/repl_2.12-jars/commons-codec-1.9.jar,file:/usr/lib/livy/repl_2.12-jars/livy-core_2.12-0.7.0-incubating.jar,file:/usr/lib/livy/repl_2.12-jars/livy-repl_2.12-0.7.0-incubating.jar'), ('spark.yarn.dist.jars', 'file:///usr/lib/livy/rsc-jars/livy-api-0.7.0-incubating.jar,file:///usr/lib/livy/rsc-jars/livy-rsc-0.7.0-incubating.jar,file:///usr/lib/livy/rsc-jars/livy-thriftserver-session-0.7.0-incubating.jar,file:///usr/lib/livy/rsc-jars/netty-all-4.1.17.Final.jar,file:///usr/lib/livy/repl_2.12-jars/commons-codec-1.9.jar,file:///usr/lib/livy/repl_2.12-jars/livy-core_2.12-0.7.0-incubating.jar,file:///usr/lib/livy/repl_2.12-jars/livy-repl_2.12-0.7.0-incubating.jar'), ('spark.yarn.executor.memoryOverheadFactor', '0.1875'), ('spark.sql.parquet.output.committer.class', 'com.amazon.emr.committer.EmrOptimizedSparkSqlParquetOutputCommitter'), ('spark.yarn.historyServer.address', 'ip-172-31-9-23.eu-west-3.compute.internal:18080'), ('spark.driver.extraClassPath', '/usr/lib/hadoop-lzo/lib/*:/usr/lib/hadoop/hadoop-aws.jar:/usr/share/aws/aws-java-sdk/*:/usr/share/aws/emr/emrfs/conf:/usr/share/aws/emr/emrfs/lib/*:/usr/share/aws/emr/emrfs/auxlib/*:/usr/share/aws/emr/goodies/lib/emr-spark-goodies.jar:/usr/share/aws/emr/security/conf:/usr/share/aws/emr/security/lib/*:/usr/share/aws/hmclient/lib/aws-glue-datacatalog-spark-client.jar:/usr/share/java/Hive-JSON-Serde/hive-openx-serde.jar:/usr/share/aws/sagemaker-spark-sdk/lib/sagemaker-spark-sdk.jar:/usr/share/aws/emr/s3select/lib/emr-s3-select-spark-connector.jar:/docker/usr/lib/hadoop-lzo/lib/*:/docker/usr/lib/hadoop/hadoop-aws.jar:/docker/usr/share/aws/aws-java-sdk/*:/docker/usr/share/aws/emr/emrfs/conf:/docker/usr/share/aws/emr/emrfs/lib/*:/docker/usr/share/aws/emr/emrfs/auxlib/*:/docker/usr/share/aws/emr/goodies/lib/emr-spark-goodies.jar:/docker/usr/share/aws/emr/security/conf:/docker/usr/share/aws/emr/security/lib/*:/docker/usr/share/aws/hmclient/lib/aws-glue-datacatalog-spark-client.jar:/docker/usr/share/java/Hive-JSON-Serde/hive-openx-serde.jar:/docker/usr/share/aws/sagemaker-spark-sdk/lib/sagemaker-spark-sdk.jar:/docker/usr/share/aws/emr/s3select/lib/emr-s3-select-spark-connector.jar'), ('spark.blacklist.decommissioning.timeout', '1h'), ('spark.yarn.appMasterEnv.SPARK_PUBLIC_DNS', '$(hostname -f)'), ('spark.yarn.dist.pyFiles', 'file:///usr/lib/spark/python/lib/pyspark.zip,file:///usr/lib/spark/python/lib/py4j-0.10.9-src.zip'), ('spark.sql.emr.internal.extensions', 'com.amazonaws.emr.spark.EmrSparkSessionExtensions'), ('spark.executorEnv.PYTHONPATH', '{{PWD}}/pyspark.zip<CPS>{{PWD}}/py4j-0.10.9-src.zip<CPS>{{PWD}}/pyspark.zip<CPS>{{PWD}}/py4j-0.10.9-src.zip'), ('spark.executor.defaultJavaOptions', \"-verbose:gc -XX:+PrintGCDetails -XX:+PrintGCDateStamps -XX:OnOutOfMemoryError='kill -9 %p' -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:MaxHeapFreeRatio=70 -XX:+CMSClassUnloadingEnabled\"), ('spark.eventLog.dir', 'hdfs:///var/log/spark/apps'), ('spark.sql.warehouse.dir', 'hdfs:///user/spark/warehouse'), ('spark.repl.local.jars', 'file:///usr/lib/livy/rsc-jars/livy-api-0.7.0-incubating.jar,file:///usr/lib/livy/rsc-jars/livy-rsc-0.7.0-incubating.jar,file:///usr/lib/livy/rsc-jars/livy-thriftserver-session-0.7.0-incubating.jar,file:///usr/lib/livy/rsc-jars/netty-all-4.1.17.Final.jar,file:///usr/lib/livy/repl_2.12-jars/commons-codec-1.9.jar,file:///usr/lib/livy/repl_2.12-jars/livy-core_2.12-0.7.0-incubating.jar,file:///usr/lib/livy/repl_2.12-jars/livy-repl_2.12-0.7.0-incubating.jar'), ('spark.history.fs.logDirectory', 'hdfs:///var/log/spark/apps'), ('spark.ui.filters', 'org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter'), ('spark.executor.extraLibraryPath', '/usr/lib/hadoop/lib/native:/usr/lib/hadoop-lzo/lib/native:/docker/usr/lib/hadoop/lib/native:/docker/usr/lib/hadoop-lzo/lib/native'), ('spark.hadoop.yarn.timeline-service.enabled', 'false'), ('spark.executor.id', 'driver'), ('spark.ui.proxyBase', '/proxy/application_1602760145222_25365'), ('spark.app.name', 'livy-session-43'), ('spark.yarn.tags', 'livy-session-43-UUrRk5YI'), ('spark.decommissioning.timeout.threshold', '20'), ('spark.sql.catalogImplementation', 'hive'), ('spark.stage.attempt.ignoreOnDecommissionFetchFailure', 'true'), ('spark.hadoop.fs.s3.getObject.initialSocketTimeoutMilliseconds', '2000'), ('spark.driver.memory', '1000M'), ('spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version.emr_internal_use_only.EmrFileSystem', '2'), ('spark.org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter.param.PROXY_URI_BASES', 'http://ip-172-31-9-23.eu-west-3.compute.internal:20888/proxy/application_1602760145222_25365'), ('spark.yarn.submit.waitAppCompletion', 'false'), ('spark.driver.port', '44943'), ('spark.yarn.dist.archives', 'file:/usr/lib/spark/R/lib/sparkr.zip#sparkr'), ('spark.executor.extraClassPath', '/usr/lib/hadoop-lzo/lib/*:/usr/lib/hadoop/hadoop-aws.jar:/usr/share/aws/aws-java-sdk/*:/usr/share/aws/emr/emrfs/conf:/usr/share/aws/emr/emrfs/lib/*:/usr/share/aws/emr/emrfs/auxlib/*:/usr/share/aws/emr/goodies/lib/emr-spark-goodies.jar:/usr/share/aws/emr/security/conf:/usr/share/aws/emr/security/lib/*:/usr/share/aws/hmclient/lib/aws-glue-datacatalog-spark-client.jar:/usr/share/java/Hive-JSON-Serde/hive-openx-serde.jar:/usr/share/aws/sagemaker-spark-sdk/lib/sagemaker-spark-sdk.jar:/usr/share/aws/emr/s3select/lib/emr-s3-select-spark-connector.jar:/docker/usr/lib/hadoop-lzo/lib/*:/docker/usr/lib/hadoop/hadoop-aws.jar:/docker/usr/share/aws/aws-java-sdk/*:/docker/usr/share/aws/emr/emrfs/conf:/docker/usr/share/aws/emr/emrfs/lib/*:/docker/usr/share/aws/emr/emrfs/auxlib/*:/docker/usr/share/aws/emr/goodies/lib/emr-spark-goodies.jar:/docker/usr/share/aws/emr/security/conf:/docker/usr/share/aws/emr/security/lib/*:/docker/usr/share/aws/hmclient/lib/aws-glue-datacatalog-spark-client.jar:/docker/usr/share/java/Hive-JSON-Serde/hive-openx-serde.jar:/docker/usr/share/aws/sagemaker-spark-sdk/lib/sagemaker-spark-sdk.jar:/docker/usr/share/aws/emr/s3select/lib/emr-s3-select-spark-connector.jar'), ('spark.app.id', 'application_1602760145222_25365'), ('spark.yarn.maxAppAttempts', '1'), ('spark.driver.appUIAddress', 'http://ip-172-31-9-23.eu-west-3.compute.internal:4040'), ('spark.sql.hive.metastore.sharedPrefixes', 'com.amazonaws.services.dynamodbv2'), ('spark.repl.class.outputDir', '/tmp/spark5518122085389851967'), ('spark.submit.deployMode', 'client'), ('spark.sql.parquet.fs.optimized.committer.optimization-enabled', 'true'), ('spark.driver.extraLibraryPath', '/usr/lib/hadoop/lib/native:/usr/lib/hadoop-lzo/lib/native:/docker/usr/lib/hadoop/lib/native:/docker/usr/lib/hadoop-lzo/lib/native'), ('spark.driver.host', 'ip-172-31-9-23.eu-west-3.compute.internal'), ('spark.livy.spark_major_version', '3'), ('spark.hadoop.mapreduce.fileoutputcommitter.cleanup-failures.ignored.emr_internal_use_only.EmrFileSystem', 'true'), ('spark.org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter.param.PROXY_HOSTS', 'ip-172-31-9-23.eu-west-3.compute.internal'), ('spark.history.ui.port', '18080'), ('spark.shuffle.service.enabled', 'true'), ('spark.resourceManager.cleanupExpiredHost', 'true'), ('spark.executor.cores', '2'), ('spark.files.fetchFailure.unRegisterOutputOnHost', 'true'), ('spark.driver.defaultJavaOptions', \"-XX:OnOutOfMemoryError='kill -9 %p' -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:MaxHeapFreeRatio=70 -XX:+CMSClassUnloadingEnabled\"), ('spark.master', 'yarn'), ('spark.yarn.secondary.jars', 'livy-api-0.7.0-incubating.jar,livy-rsc-0.7.0-incubating.jar,livy-thriftserver-session-0.7.0-incubating.jar,netty-all-4.1.17.Final.jar,commons-codec-1.9.jar,livy-core_2.12-0.7.0-incubating.jar,livy-repl_2.12-0.7.0-incubating.jar'), ('spark.yarn.isPython', 'true'), ('spark.repl.class.uri', 'spark://ip-172-31-9-23.eu-west-3.compute.internal:44943/classes'), ('spark.dynamicAllocation.enabled', 'true'), ('spark.blacklist.decommissioning.enabled', 'true')]"
     ]
    }
   ],
   "source": [
    "spark.sparkContext.getConf().getAll()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('spark.submit.pyFiles',\n",
      "  '/usr/lib/spark/python/lib/pyspark.zip,/usr/lib/spark/python/lib/py4j-0.10.9-src.zip'),\n",
      " ('spark.eventLog.enabled', 'true'),\n",
      " ('spark.executor.memory', '9486M'),\n",
      " ('spark.jars',\n",
      "  'file:/usr/lib/livy/rsc-jars/livy-api-0.7.0-incubating.jar,file:/usr/lib/livy/rsc-jars/livy-rsc-0.7.0-incubating.jar,file:/usr/lib/livy/rsc-jars/livy-thriftserver-session-0.7.0-incubating.jar,file:/usr/lib/livy/rsc-jars/netty-all-4.1.17.Final.jar,file:/usr/lib/livy/repl_2.12-jars/commons-codec-1.9.jar,file:/usr/lib/livy/repl_2.12-jars/livy-core_2.12-0.7.0-incubating.jar,file:/usr/lib/livy/repl_2.12-jars/livy-repl_2.12-0.7.0-incubating.jar'),\n",
      " ('spark.yarn.dist.jars',\n",
      "  'file:///usr/lib/livy/rsc-jars/livy-api-0.7.0-incubating.jar,file:///usr/lib/livy/rsc-jars/livy-rsc-0.7.0-incubating.jar,file:///usr/lib/livy/rsc-jars/livy-thriftserver-session-0.7.0-incubating.jar,file:///usr/lib/livy/rsc-jars/netty-all-4.1.17.Final.jar,file:///usr/lib/livy/repl_2.12-jars/commons-codec-1.9.jar,file:///usr/lib/livy/repl_2.12-jars/livy-core_2.12-0.7.0-incubating.jar,file:///usr/lib/livy/repl_2.12-jars/livy-repl_2.12-0.7.0-incubating.jar'),\n",
      " ('spark.yarn.executor.memoryOverheadFactor', '0.1875'),\n",
      " ('spark.sql.parquet.output.committer.class',\n",
      "  'com.amazon.emr.committer.EmrOptimizedSparkSqlParquetOutputCommitter'),\n",
      " ('spark.yarn.historyServer.address',\n",
      "  'ip-172-31-9-23.eu-west-3.compute.internal:18080'),\n",
      " ('spark.driver.extraClassPath',\n",
      "  '/usr/lib/hadoop-lzo/lib/*:/usr/lib/hadoop/hadoop-aws.jar:/usr/share/aws/aws-java-sdk/*:/usr/share/aws/emr/emrfs/conf:/usr/share/aws/emr/emrfs/lib/*:/usr/share/aws/emr/emrfs/auxlib/*:/usr/share/aws/emr/goodies/lib/emr-spark-goodies.jar:/usr/share/aws/emr/security/conf:/usr/share/aws/emr/security/lib/*:/usr/share/aws/hmclient/lib/aws-glue-datacatalog-spark-client.jar:/usr/share/java/Hive-JSON-Serde/hive-openx-serde.jar:/usr/share/aws/sagemaker-spark-sdk/lib/sagemaker-spark-sdk.jar:/usr/share/aws/emr/s3select/lib/emr-s3-select-spark-connector.jar:/docker/usr/lib/hadoop-lzo/lib/*:/docker/usr/lib/hadoop/hadoop-aws.jar:/docker/usr/share/aws/aws-java-sdk/*:/docker/usr/share/aws/emr/emrfs/conf:/docker/usr/share/aws/emr/emrfs/lib/*:/docker/usr/share/aws/emr/emrfs/auxlib/*:/docker/usr/share/aws/emr/goodies/lib/emr-spark-goodies.jar:/docker/usr/share/aws/emr/security/conf:/docker/usr/share/aws/emr/security/lib/*:/docker/usr/share/aws/hmclient/lib/aws-glue-datacatalog-spark-client.jar:/docker/usr/share/java/Hive-JSON-Serde/hive-openx-serde.jar:/docker/usr/share/aws/sagemaker-spark-sdk/lib/sagemaker-spark-sdk.jar:/docker/usr/share/aws/emr/s3select/lib/emr-s3-select-spark-connector.jar'),\n",
      " ('spark.blacklist.decommissioning.timeout', '1h'),\n",
      " ('spark.yarn.appMasterEnv.SPARK_PUBLIC_DNS', '$(hostname -f)'),\n",
      " ('spark.yarn.dist.pyFiles',\n",
      "  'file:///usr/lib/spark/python/lib/pyspark.zip,file:///usr/lib/spark/python/lib/py4j-0.10.9-src.zip'),\n",
      " ('spark.sql.emr.internal.extensions',\n",
      "  'com.amazonaws.emr.spark.EmrSparkSessionExtensions'),\n",
      " ('spark.executorEnv.PYTHONPATH',\n",
      "  '{{PWD}}/pyspark.zip<CPS>{{PWD}}/py4j-0.10.9-src.zip<CPS>{{PWD}}/pyspark.zip<CPS>{{PWD}}/py4j-0.10.9-src.zip'),\n",
      " ('spark.executor.defaultJavaOptions',\n",
      "  '-verbose:gc -XX:+PrintGCDetails -XX:+PrintGCDateStamps '\n",
      "  \"-XX:OnOutOfMemoryError='kill -9 %p' -XX:+UseConcMarkSweepGC \"\n",
      "  '-XX:CMSInitiatingOccupancyFraction=70 -XX:MaxHeapFreeRatio=70 '\n",
      "  '-XX:+CMSClassUnloadingEnabled'),\n",
      " ('spark.eventLog.dir', 'hdfs:///var/log/spark/apps'),\n",
      " ('spark.sql.warehouse.dir', 'hdfs:///user/spark/warehouse'),\n",
      " ('spark.repl.local.jars',\n",
      "  'file:///usr/lib/livy/rsc-jars/livy-api-0.7.0-incubating.jar,file:///usr/lib/livy/rsc-jars/livy-rsc-0.7.0-incubating.jar,file:///usr/lib/livy/rsc-jars/livy-thriftserver-session-0.7.0-incubating.jar,file:///usr/lib/livy/rsc-jars/netty-all-4.1.17.Final.jar,file:///usr/lib/livy/repl_2.12-jars/commons-codec-1.9.jar,file:///usr/lib/livy/repl_2.12-jars/livy-core_2.12-0.7.0-incubating.jar,file:///usr/lib/livy/repl_2.12-jars/livy-repl_2.12-0.7.0-incubating.jar'),\n",
      " ('spark.history.fs.logDirectory', 'hdfs:///var/log/spark/apps'),\n",
      " ('spark.ui.filters',\n",
      "  'org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter'),\n",
      " ('spark.executor.extraLibraryPath',\n",
      "  '/usr/lib/hadoop/lib/native:/usr/lib/hadoop-lzo/lib/native:/docker/usr/lib/hadoop/lib/native:/docker/usr/lib/hadoop-lzo/lib/native'),\n",
      " ('spark.hadoop.yarn.timeline-service.enabled', 'false'),\n",
      " ('spark.executor.id', 'driver'),\n",
      " ('spark.ui.proxyBase', '/proxy/application_1602760145222_25365'),\n",
      " ('spark.app.name', 'livy-session-43'),\n",
      " ('spark.yarn.tags', 'livy-session-43-UUrRk5YI'),\n",
      " ('spark.decommissioning.timeout.threshold', '20'),\n",
      " ('spark.sql.catalogImplementation', 'hive'),\n",
      " ('spark.stage.attempt.ignoreOnDecommissionFetchFailure', 'true'),\n",
      " ('spark.hadoop.fs.s3.getObject.initialSocketTimeoutMilliseconds', '2000'),\n",
      " ('spark.driver.memory', '1000M'),\n",
      " ('spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version.emr_internal_use_only.EmrFileSystem',\n",
      "  '2'),\n",
      " ('spark.org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter.param.PROXY_URI_BASES',\n",
      "  'http://ip-172-31-9-23.eu-west-3.compute.internal:20888/proxy/application_1602760145222_25365'),\n",
      " ('spark.yarn.submit.waitAppCompletion', 'false'),\n",
      " ('spark.driver.port', '44943'),\n",
      " ('spark.yarn.dist.archives', 'file:/usr/lib/spark/R/lib/sparkr.zip#sparkr'),\n",
      " ('spark.executor.extraClassPath',\n",
      "  '/usr/lib/hadoop-lzo/lib/*:/usr/lib/hadoop/hadoop-aws.jar:/usr/share/aws/aws-java-sdk/*:/usr/share/aws/emr/emrfs/conf:/usr/share/aws/emr/emrfs/lib/*:/usr/share/aws/emr/emrfs/auxlib/*:/usr/share/aws/emr/goodies/lib/emr-spark-goodies.jar:/usr/share/aws/emr/security/conf:/usr/share/aws/emr/security/lib/*:/usr/share/aws/hmclient/lib/aws-glue-datacatalog-spark-client.jar:/usr/share/java/Hive-JSON-Serde/hive-openx-serde.jar:/usr/share/aws/sagemaker-spark-sdk/lib/sagemaker-spark-sdk.jar:/usr/share/aws/emr/s3select/lib/emr-s3-select-spark-connector.jar:/docker/usr/lib/hadoop-lzo/lib/*:/docker/usr/lib/hadoop/hadoop-aws.jar:/docker/usr/share/aws/aws-java-sdk/*:/docker/usr/share/aws/emr/emrfs/conf:/docker/usr/share/aws/emr/emrfs/lib/*:/docker/usr/share/aws/emr/emrfs/auxlib/*:/docker/usr/share/aws/emr/goodies/lib/emr-spark-goodies.jar:/docker/usr/share/aws/emr/security/conf:/docker/usr/share/aws/emr/security/lib/*:/docker/usr/share/aws/hmclient/lib/aws-glue-datacatalog-spark-client.jar:/docker/usr/share/java/Hive-JSON-Serde/hive-openx-serde.jar:/docker/usr/share/aws/sagemaker-spark-sdk/lib/sagemaker-spark-sdk.jar:/docker/usr/share/aws/emr/s3select/lib/emr-s3-select-spark-connector.jar'),\n",
      " ('spark.app.id', 'application_1602760145222_25365'),\n",
      " ('spark.yarn.maxAppAttempts', '1'),\n",
      " ('spark.driver.appUIAddress',\n",
      "  'http://ip-172-31-9-23.eu-west-3.compute.internal:4040'),\n",
      " ('spark.sql.hive.metastore.sharedPrefixes',\n",
      "  'com.amazonaws.services.dynamodbv2'),\n",
      " ('spark.repl.class.outputDir', '/tmp/spark5518122085389851967'),\n",
      " ('spark.submit.deployMode', 'client'),\n",
      " ('spark.sql.parquet.fs.optimized.committer.optimization-enabled', 'true'),\n",
      " ('spark.driver.extraLibraryPath',\n",
      "  '/usr/lib/hadoop/lib/native:/usr/lib/hadoop-lzo/lib/native:/docker/usr/lib/hadoop/lib/native:/docker/usr/lib/hadoop-lzo/lib/native'),\n",
      " ('spark.driver.host', 'ip-172-31-9-23.eu-west-3.compute.internal'),\n",
      " ('spark.livy.spark_major_version', '3'),\n",
      " ('spark.hadoop.mapreduce.fileoutputcommitter.cleanup-failures.ignored.emr_internal_use_only.EmrFileSystem',\n",
      "  'true'),\n",
      " ('spark.org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter.param.PROXY_HOSTS',\n",
      "  'ip-172-31-9-23.eu-west-3.compute.internal'),\n",
      " ('spark.history.ui.port', '18080'),\n",
      " ('spark.shuffle.service.enabled', 'true'),\n",
      " ('spark.resourceManager.cleanupExpiredHost', 'true'),\n",
      " ('spark.executor.cores', '2'),\n",
      " ('spark.files.fetchFailure.unRegisterOutputOnHost', 'true'),\n",
      " ('spark.driver.defaultJavaOptions',\n",
      "  \"-XX:OnOutOfMemoryError='kill -9 %p' -XX:+UseConcMarkSweepGC \"\n",
      "  '-XX:CMSInitiatingOccupancyFraction=70 -XX:MaxHeapFreeRatio=70 '\n",
      "  '-XX:+CMSClassUnloadingEnabled'),\n",
      " ('spark.master', 'yarn'),\n",
      " ('spark.yarn.secondary.jars',\n",
      "  'livy-api-0.7.0-incubating.jar,livy-rsc-0.7.0-incubating.jar,livy-thriftserver-session-0.7.0-incubating.jar,netty-all-4.1.17.Final.jar,commons-codec-1.9.jar,livy-core_2.12-0.7.0-incubating.jar,livy-repl_2.12-0.7.0-incubating.jar'),\n",
      " ('spark.yarn.isPython', 'true'),\n",
      " ('spark.repl.class.uri',\n",
      "  'spark://ip-172-31-9-23.eu-west-3.compute.internal:44943/classes'),\n",
      " ('spark.dynamicAllocation.enabled', 'true'),\n",
      " ('spark.blacklist.decommissioning.enabled', 'true')]"
     ]
    }
   ],
   "source": [
    "pprint(spark.sparkContext.getConf().getAll())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>44</td><td>application_1602760145222_25382</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-172-31-9-23.eu-west-3.compute.internal:20888/proxy/application_1602760145222_25382/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-172-31-6-132.eu-west-3.compute.internal:8042/node/containerlogs/container_1602760145222_25382_01_000001/livy\">Link</a></td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Current session configs: <tt>{'executorMemory': '1g', 'executorCores': 1, 'numExecutors': 1, 'proxyUser': 'jovyan', 'kind': 'pyspark'}</tt><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>44</td><td>application_1602760145222_25382</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-172-31-9-23.eu-west-3.compute.internal:20888/proxy/application_1602760145222_25382/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-172-31-6-132.eu-west-3.compute.internal:8042/node/containerlogs/container_1602760145222_25382_01_000001/livy\">Link</a></td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%configure -f\n",
    "{\"executorMemory\": \"1g\", \"executorCores\": 1, \"numExecutors\":1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('spark.submit.pyFiles',\n",
      "  '/usr/lib/spark/python/lib/pyspark.zip,/usr/lib/spark/python/lib/py4j-0.10.9-src.zip'),\n",
      " ('spark.eventLog.enabled', 'true'),\n",
      " ('spark.jars',\n",
      "  'file:/usr/lib/livy/rsc-jars/livy-api-0.7.0-incubating.jar,file:/usr/lib/livy/rsc-jars/livy-rsc-0.7.0-incubating.jar,file:/usr/lib/livy/rsc-jars/livy-thriftserver-session-0.7.0-incubating.jar,file:/usr/lib/livy/rsc-jars/netty-all-4.1.17.Final.jar,file:/usr/lib/livy/repl_2.12-jars/commons-codec-1.9.jar,file:/usr/lib/livy/repl_2.12-jars/livy-core_2.12-0.7.0-incubating.jar,file:/usr/lib/livy/repl_2.12-jars/livy-repl_2.12-0.7.0-incubating.jar'),\n",
      " ('spark.yarn.dist.jars',\n",
      "  'file:///usr/lib/livy/rsc-jars/livy-api-0.7.0-incubating.jar,file:///usr/lib/livy/rsc-jars/livy-rsc-0.7.0-incubating.jar,file:///usr/lib/livy/rsc-jars/livy-thriftserver-session-0.7.0-incubating.jar,file:///usr/lib/livy/rsc-jars/netty-all-4.1.17.Final.jar,file:///usr/lib/livy/repl_2.12-jars/commons-codec-1.9.jar,file:///usr/lib/livy/repl_2.12-jars/livy-core_2.12-0.7.0-incubating.jar,file:///usr/lib/livy/repl_2.12-jars/livy-repl_2.12-0.7.0-incubating.jar'),\n",
      " ('spark.driver.port', '33027'),\n",
      " ('spark.yarn.executor.memoryOverheadFactor', '0.1875'),\n",
      " ('spark.sql.parquet.output.committer.class',\n",
      "  'com.amazon.emr.committer.EmrOptimizedSparkSqlParquetOutputCommitter'),\n",
      " ('spark.yarn.historyServer.address',\n",
      "  'ip-172-31-9-23.eu-west-3.compute.internal:18080'),\n",
      " ('spark.driver.extraClassPath',\n",
      "  '/usr/lib/hadoop-lzo/lib/*:/usr/lib/hadoop/hadoop-aws.jar:/usr/share/aws/aws-java-sdk/*:/usr/share/aws/emr/emrfs/conf:/usr/share/aws/emr/emrfs/lib/*:/usr/share/aws/emr/emrfs/auxlib/*:/usr/share/aws/emr/goodies/lib/emr-spark-goodies.jar:/usr/share/aws/emr/security/conf:/usr/share/aws/emr/security/lib/*:/usr/share/aws/hmclient/lib/aws-glue-datacatalog-spark-client.jar:/usr/share/java/Hive-JSON-Serde/hive-openx-serde.jar:/usr/share/aws/sagemaker-spark-sdk/lib/sagemaker-spark-sdk.jar:/usr/share/aws/emr/s3select/lib/emr-s3-select-spark-connector.jar:/docker/usr/lib/hadoop-lzo/lib/*:/docker/usr/lib/hadoop/hadoop-aws.jar:/docker/usr/share/aws/aws-java-sdk/*:/docker/usr/share/aws/emr/emrfs/conf:/docker/usr/share/aws/emr/emrfs/lib/*:/docker/usr/share/aws/emr/emrfs/auxlib/*:/docker/usr/share/aws/emr/goodies/lib/emr-spark-goodies.jar:/docker/usr/share/aws/emr/security/conf:/docker/usr/share/aws/emr/security/lib/*:/docker/usr/share/aws/hmclient/lib/aws-glue-datacatalog-spark-client.jar:/docker/usr/share/java/Hive-JSON-Serde/hive-openx-serde.jar:/docker/usr/share/aws/sagemaker-spark-sdk/lib/sagemaker-spark-sdk.jar:/docker/usr/share/aws/emr/s3select/lib/emr-s3-select-spark-connector.jar'),\n",
      " ('spark.blacklist.decommissioning.timeout', '1h'),\n",
      " ('spark.yarn.appMasterEnv.SPARK_PUBLIC_DNS', '$(hostname -f)'),\n",
      " ('spark.yarn.dist.pyFiles',\n",
      "  'file:///usr/lib/spark/python/lib/pyspark.zip,file:///usr/lib/spark/python/lib/py4j-0.10.9-src.zip'),\n",
      " ('spark.sql.emr.internal.extensions',\n",
      "  'com.amazonaws.emr.spark.EmrSparkSessionExtensions'),\n",
      " ('spark.executorEnv.PYTHONPATH',\n",
      "  '{{PWD}}/pyspark.zip<CPS>{{PWD}}/py4j-0.10.9-src.zip<CPS>{{PWD}}/pyspark.zip<CPS>{{PWD}}/py4j-0.10.9-src.zip'),\n",
      " ('spark.executor.defaultJavaOptions',\n",
      "  '-verbose:gc -XX:+PrintGCDetails -XX:+PrintGCDateStamps '\n",
      "  \"-XX:OnOutOfMemoryError='kill -9 %p' -XX:+UseConcMarkSweepGC \"\n",
      "  '-XX:CMSInitiatingOccupancyFraction=70 -XX:MaxHeapFreeRatio=70 '\n",
      "  '-XX:+CMSClassUnloadingEnabled'),\n",
      " ('spark.eventLog.dir', 'hdfs:///var/log/spark/apps'),\n",
      " ('spark.executor.memory', '1g'),\n",
      " ('spark.sql.warehouse.dir', 'hdfs:///user/spark/warehouse'),\n",
      " ('spark.repl.local.jars',\n",
      "  'file:///usr/lib/livy/rsc-jars/livy-api-0.7.0-incubating.jar,file:///usr/lib/livy/rsc-jars/livy-rsc-0.7.0-incubating.jar,file:///usr/lib/livy/rsc-jars/livy-thriftserver-session-0.7.0-incubating.jar,file:///usr/lib/livy/rsc-jars/netty-all-4.1.17.Final.jar,file:///usr/lib/livy/repl_2.12-jars/commons-codec-1.9.jar,file:///usr/lib/livy/repl_2.12-jars/livy-core_2.12-0.7.0-incubating.jar,file:///usr/lib/livy/repl_2.12-jars/livy-repl_2.12-0.7.0-incubating.jar'),\n",
      " ('spark.history.fs.logDirectory', 'hdfs:///var/log/spark/apps'),\n",
      " ('spark.ui.filters',\n",
      "  'org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter'),\n",
      " ('spark.executor.extraLibraryPath',\n",
      "  '/usr/lib/hadoop/lib/native:/usr/lib/hadoop-lzo/lib/native:/docker/usr/lib/hadoop/lib/native:/docker/usr/lib/hadoop-lzo/lib/native'),\n",
      " ('spark.hadoop.yarn.timeline-service.enabled', 'false'),\n",
      " ('spark.executor.id', 'driver'),\n",
      " ('spark.driver.memory', '2048M'),\n",
      " ('spark.decommissioning.timeout.threshold', '20'),\n",
      " ('spark.sql.catalogImplementation', 'hive'),\n",
      " ('spark.app.name', 'livy-session-44'),\n",
      " ('spark.stage.attempt.ignoreOnDecommissionFetchFailure', 'true'),\n",
      " ('spark.executor.instances', '1'),\n",
      " ('spark.hadoop.fs.s3.getObject.initialSocketTimeoutMilliseconds', '2000'),\n",
      " ('spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version.emr_internal_use_only.EmrFileSystem',\n",
      "  '2'),\n",
      " ('spark.repl.class.uri',\n",
      "  'spark://ip-172-31-9-23.eu-west-3.compute.internal:33027/classes'),\n",
      " ('spark.yarn.submit.waitAppCompletion', 'false'),\n",
      " ('spark.org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter.param.PROXY_URI_BASES',\n",
      "  'http://ip-172-31-9-23.eu-west-3.compute.internal:20888/proxy/application_1602760145222_25382'),\n",
      " ('spark.repl.class.outputDir', '/tmp/spark259790349293982580'),\n",
      " ('spark.yarn.dist.archives', 'file:/usr/lib/spark/R/lib/sparkr.zip#sparkr'),\n",
      " ('spark.ui.proxyBase', '/proxy/application_1602760145222_25382'),\n",
      " ('spark.executor.extraClassPath',\n",
      "  '/usr/lib/hadoop-lzo/lib/*:/usr/lib/hadoop/hadoop-aws.jar:/usr/share/aws/aws-java-sdk/*:/usr/share/aws/emr/emrfs/conf:/usr/share/aws/emr/emrfs/lib/*:/usr/share/aws/emr/emrfs/auxlib/*:/usr/share/aws/emr/goodies/lib/emr-spark-goodies.jar:/usr/share/aws/emr/security/conf:/usr/share/aws/emr/security/lib/*:/usr/share/aws/hmclient/lib/aws-glue-datacatalog-spark-client.jar:/usr/share/java/Hive-JSON-Serde/hive-openx-serde.jar:/usr/share/aws/sagemaker-spark-sdk/lib/sagemaker-spark-sdk.jar:/usr/share/aws/emr/s3select/lib/emr-s3-select-spark-connector.jar:/docker/usr/lib/hadoop-lzo/lib/*:/docker/usr/lib/hadoop/hadoop-aws.jar:/docker/usr/share/aws/aws-java-sdk/*:/docker/usr/share/aws/emr/emrfs/conf:/docker/usr/share/aws/emr/emrfs/lib/*:/docker/usr/share/aws/emr/emrfs/auxlib/*:/docker/usr/share/aws/emr/goodies/lib/emr-spark-goodies.jar:/docker/usr/share/aws/emr/security/conf:/docker/usr/share/aws/emr/security/lib/*:/docker/usr/share/aws/hmclient/lib/aws-glue-datacatalog-spark-client.jar:/docker/usr/share/java/Hive-JSON-Serde/hive-openx-serde.jar:/docker/usr/share/aws/sagemaker-spark-sdk/lib/sagemaker-spark-sdk.jar:/docker/usr/share/aws/emr/s3select/lib/emr-s3-select-spark-connector.jar'),\n",
      " ('spark.yarn.maxAppAttempts', '1'),\n",
      " ('spark.driver.appUIAddress',\n",
      "  'http://ip-172-31-9-23.eu-west-3.compute.internal:4040'),\n",
      " ('spark.sql.hive.metastore.sharedPrefixes',\n",
      "  'com.amazonaws.services.dynamodbv2'),\n",
      " ('spark.submit.deployMode', 'client'),\n",
      " ('spark.sql.parquet.fs.optimized.committer.optimization-enabled', 'true'),\n",
      " ('spark.driver.extraLibraryPath',\n",
      "  '/usr/lib/hadoop/lib/native:/usr/lib/hadoop-lzo/lib/native:/docker/usr/lib/hadoop/lib/native:/docker/usr/lib/hadoop-lzo/lib/native'),\n",
      " ('spark.driver.host', 'ip-172-31-9-23.eu-west-3.compute.internal'),\n",
      " ('spark.livy.spark_major_version', '3'),\n",
      " ('spark.hadoop.mapreduce.fileoutputcommitter.cleanup-failures.ignored.emr_internal_use_only.EmrFileSystem',\n",
      "  'true'),\n",
      " ('spark.app.id', 'application_1602760145222_25382'),\n",
      " ('spark.org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter.param.PROXY_HOSTS',\n",
      "  'ip-172-31-9-23.eu-west-3.compute.internal'),\n",
      " ('spark.history.ui.port', '18080'),\n",
      " ('spark.shuffle.service.enabled', 'true'),\n",
      " ('spark.resourceManager.cleanupExpiredHost', 'true'),\n",
      " ('spark.files.fetchFailure.unRegisterOutputOnHost', 'true'),\n",
      " ('spark.yarn.tags', 'livy-session-44-Jt0AwzlH'),\n",
      " ('spark.driver.defaultJavaOptions',\n",
      "  \"-XX:OnOutOfMemoryError='kill -9 %p' -XX:+UseConcMarkSweepGC \"\n",
      "  '-XX:CMSInitiatingOccupancyFraction=70 -XX:MaxHeapFreeRatio=70 '\n",
      "  '-XX:+CMSClassUnloadingEnabled'),\n",
      " ('spark.master', 'yarn'),\n",
      " ('spark.yarn.secondary.jars',\n",
      "  'livy-api-0.7.0-incubating.jar,livy-rsc-0.7.0-incubating.jar,livy-thriftserver-session-0.7.0-incubating.jar,netty-all-4.1.17.Final.jar,commons-codec-1.9.jar,livy-core_2.12-0.7.0-incubating.jar,livy-repl_2.12-0.7.0-incubating.jar'),\n",
      " ('spark.yarn.isPython', 'true'),\n",
      " ('spark.dynamicAllocation.enabled', 'true'),\n",
      " ('spark.executor.cores', '1'),\n",
      " ('spark.blacklist.decommissioning.enabled', 'true')]"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "pprint(spark.sparkContext.getConf().getAll())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
